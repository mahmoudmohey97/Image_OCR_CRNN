{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefefd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import data, img_utils, text_utils, model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1548df",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTERS = \"اآأدذجحخهعغفقثصضطكمنتلبيسشظزوةىلارؤءئ \"\n",
    "BASE_PATH = \"..\\..\\OCR_fName_Task_Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = data.ReadData(BASE_PATH)\n",
    "image_obj = img_utils.ImageProcessingUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2677501",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data_reader.parse_data_from_folder()\n",
    "print('Files Count:', len(data_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find text of max length\n",
    "max_label_length = 0\n",
    "\n",
    "#lists for train dataset\n",
    "train_images = []\n",
    "train_text = []\n",
    "train_text_length = []\n",
    "train_input_length = []\n",
    "original_text = []\n",
    "\n",
    "\n",
    "#lists for validation dataset\n",
    "valid_images = []\n",
    "valid_text = []\n",
    "valid_input_length = []\n",
    "valid_text_length = []\n",
    "valid_original_text = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf131e63",
   "metadata": {},
   "source": [
    "## Loop on each file to read related image then start preprocessing on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key, value in tqdm(data_dict.items()):\n",
    "    file_name = key + \".jpg\"\n",
    "    image_path = BASE_PATH + \"\\\\\" + file_name\n",
    "    text = value\n",
    "    image = image_obj.processing_pipeline(image_path)\n",
    "    \n",
    "    if image.shape != (32,128):\n",
    "        print('resize error in file:', file_name)\n",
    "        continue\n",
    "    \n",
    "    if len(text) > max_label_length:\n",
    "        max_label_length = len(text)\n",
    "    \n",
    "    if i%10 != 0:\n",
    "        original_text.append(text)\n",
    "        train_images.append(image)\n",
    "        train_text.append(text_utils.encode_to_labels(text, CHARACTERS))\n",
    "        train_text_length.append(len(text))\n",
    "        train_input_length.append(20)\n",
    "    \n",
    "    # 10% percent of data for validation\n",
    "    else:\n",
    "        valid_images.append(image)\n",
    "        valid_text.append(text_utils.encode_to_labels(text, CHARACTERS))\n",
    "        valid_text_length.append(len(text))\n",
    "        valid_input_length.append(20)\n",
    "        valid_original_text.append(text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c005c158",
   "metadata": {},
   "source": [
    "## Prepare Inputs For Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037026c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad text\n",
    "train_text_pad = text_utils.pad_text(train_text, max_label_length, pad_value=len(CHARACTERS))\n",
    "valid_text_pad = text_utils.pad_text(valid_text, max_label_length, pad_value=len(CHARACTERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff729028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Lists to Numpy Arrays\n",
    "train_images = np.array(train_images)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_text_length = np.array(train_text_length)\n",
    "\n",
    "valid_images = np.array(valid_images)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_text_length = np.array(valid_text_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b8eb4",
   "metadata": {},
   "source": [
    "## Create CRNN & Add CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='labels', shape=[max_label_length], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "filepath=\".\\\\content\\\\best_model_v2.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497994c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model, inputs, outputs = model_utils.create_model_architecture()\n",
    "model = model_utils.add_ctc_layer(inputs, outputs, labels, input_length, label_length)\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam', metrics='accuracy')\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                             mode='auto', metrics=['accuracy'])\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae62b6",
   "metadata": {},
   "source": [
    "## Model training for 75 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b436c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 75 \n",
    "model.fit(x=[train_images, train_text_pad, train_input_length, train_text_length],\n",
    "          y=np.zeros(len(train_images)), \n",
    "          batch_size=batch_size, epochs = epochs, \n",
    "          validation_data = ([valid_images, valid_text_pad, valid_input_length, valid_text_length], \n",
    "          [np.zeros(len(valid_images))]), verbose = 1, callbacks = callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
